#!/usr/bin/env python
# -*- coding: UTF-8 -*-

"""
@Project    ï¼šIMDBCrawler
@File       ï¼šimdb_crawler_playwright_single_threaded.py
@Author     ï¼šIronmanJay
@Date       ï¼š2025/7/4 17:21
@Describe   ï¼šä½¿ç”¨Playwrightï¼ˆå•çº¿ç¨‹ï¼‰å¯¹IMDBç½‘ç«™çš„HTMLé¡µé¢è¿›è¡Œçˆ¬å–
"""

import os
import time
import traceback
from playwright.sync_api import sync_playwright
import random

# ==== é…ç½®é¡¹ ====
ROOT_DIR = os.getcwd()
IMDB_ID_FILE = "data.txt"
OUTPUT_DIR = "debug_results"
FAILED_FILE = "failed_ids.txt"
TIMEOUT = 10000                # é¡µé¢åŠ è½½è¶…æ—¶(ms)
RETRY_COUNT = 2                # æœ€å¤§é‡è¯•æ¬¡æ•°
HEADLESS = True               # æ˜¯å¦æ— å¤´æµè§ˆå™¨

# ==== å·¥å…·å‡½æ•° ====
def read_imdb_ids_from_file(filename="data.txt"):
    filepath = os.path.join(ROOT_DIR, filename)
    imdb_ids = []
    try:
        print(f"å°è¯•ä»æ–‡ä»¶ {filepath} è¯»å–IMDb IDåˆ—è¡¨...")
        with open(filepath, "r", encoding="utf-8") as file:
            for line in file:
                line = line.strip()
                if line.startswith("tt") and len(line) >= 9:
                    imdb_ids.append(line)
        if not imdb_ids:
            raise ValueError("æ–‡ä»¶ä¸ºç©ºæˆ–æœªæ‰¾åˆ°æœ‰æ•ˆçš„IMDb ID")
        print(f"ä»æ–‡ä»¶ {filepath} è¯»å–äº† {len(imdb_ids)} ä¸ªæœ‰æ•ˆçš„IMDb ID")
        return imdb_ids
    except FileNotFoundError:
        print(f"é”™è¯¯: æ–‡ä»¶ {filepath} ä¸å­˜åœ¨")
        return []
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return []

def remove_id_from_file(imdb_id, filename="data.txt"):
    filepath = os.path.join(ROOT_DIR, filename)
    try:
        print(f"æ­£åœ¨ä» {filepath} ä¸­ç§»é™¤ID: {imdb_id}")
        with open(filepath, "r", encoding="utf-8") as file:
            lines = file.readlines()
        new_lines = [line for line in lines if line.strip() != imdb_id]
        with open(filepath, "w", encoding="utf-8") as file:
            file.writelines(new_lines)
        print(f"âœ… å·²ä» {filepath} ä¸­æˆåŠŸç§»é™¤ID: {imdb_id}")
        return True
    except Exception as e:
        print(f"âŒ ä» {filepath} ä¸­ç§»é™¤IDå¤±è´¥: {imdb_id}, åŸå› : {str(e)}")
        traceback.print_exc()
        return False

def save_html(page, imdb_id, output_dir):
    html_path = os.path.join(output_dir, f"{imdb_id}.html")
    content = page.content()
    with open(html_path, "w", encoding="utf-8") as f:
        f.write(content)
    print(f"âœ… [{imdb_id}] å·²ä¿å­˜åˆ°: {html_path}")

def is_challenge_page(html):
    return "awswaf" in html.lower() or "challenge-container" in html.lower()

def fetch_imdb_page(page, imdb_id):
    url = f"https://www.imdb.com/title/{imdb_id}/plotsummary/"

    page.set_extra_http_headers({
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
                      "(KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36",
        "Accept-Language": "en-US,en;q=0.9",
        "Referer": "https://www.imdb.com/"
    })

    for attempt in range(1, RETRY_COUNT + 1):
        try:
            print(f"ğŸŒ [{imdb_id}] ç¬¬{attempt}æ¬¡è®¿é—®: {url}")
            page.goto(url, timeout=TIMEOUT)

            try:
                page.wait_for_selector("#summaries", timeout=5000)
            except Exception:
                print(f"âš ï¸ [{imdb_id}] å‰§æƒ…åŒºå—åŠ è½½å¼‚å¸¸ï¼Œç»§ç»­ä¿å­˜HTML")

            html = page.content()

            if is_challenge_page(html):
                print(f"âš ï¸ [{imdb_id}] æ£€æµ‹åˆ°æŒ‘æˆ˜é¡µé¢ï¼Œåˆ·æ–°é‡è¯•...")
                page.reload(timeout=TIMEOUT)
                page.wait_for_selector('div[data-testid="sub-section-summaries"]', timeout=8000)
                html = page.content()
                if is_challenge_page(html):
                    raise Exception("ä»ç„¶æ˜¯æŒ‘æˆ˜é¡µ")

            return True
        except Exception as e:
            print(f"âŒ [{imdb_id}] é”™è¯¯: {str(e)}")
            if attempt < RETRY_COUNT:
                wait_sec = 3 + attempt * 2
                jitter = random.uniform(0.5, 2.5)  # å¢åŠ æŠ–åŠ¨é˜²æ­¢èŠ‚å¥è§„å¾‹
                total_wait = wait_sec + jitter
                print(f"ğŸ˜´ è®¿é—®å¤±è´¥ï¼Œç­‰å¾… {total_wait:.1f}s åé‡è¯•...\n")
                time.sleep(total_wait)
            else:
                return False
    return False

# ==== é¡ºåºçˆ¬å–ä¸»é€»è¾‘ ====
def fetch_all_sequential(imdb_ids, output_dir):
    os.makedirs(output_dir, exist_ok=True)
    failed_ids = []

    with sync_playwright() as p:
        browser = p.chromium.launch(
            headless=HEADLESS,
            args=[
                "--no-sandbox",
                "--disable-dev-shm-usage",
                "--disable-blink-features=AutomationControlled",
                "--disable-gpu"
            ]
        )
        context = browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
                       "(KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36"
        )

        # æ‹¦æˆªä¸å¿…è¦èµ„æºï¼ŒåŠ å¿«åŠ è½½é€Ÿåº¦
        context.route("**/*", lambda route, request:
            route.abort() if request.resource_type in ["image", "font", "stylesheet"]
            else route.continue_())

        # âœ… åªåˆ›å»ºä¸€ä¸ª page
        page = context.new_page()

        # âœ… è®¾ç½®ä¸€æ¬¡ headersï¼Œé¿å…é‡å¤è®¾ç½®
        page.set_extra_http_headers({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
                          "(KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36",
            "Accept-Language": "en-US,en;q=0.9",
            "Referer": "https://www.imdb.com/"
        })

        total = len(imdb_ids)
        for index, imdb_id in enumerate(imdb_ids):
            print(f"ğŸ“¥ æ­£åœ¨å¤„ç†ç¬¬ {index + 1}/{total} ä¸ª: {imdb_id}")
            try:
                success = fetch_imdb_page(page, imdb_id)
                if success:
                    save_html(page, imdb_id, output_dir)
                    remove_id_from_file(imdb_id)
                else:
                    failed_ids.append(imdb_id)
            except Exception as e:
                print(f"âŒ å¤„ç† {imdb_id} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")

        # âœ… æ‰€æœ‰å¤„ç†å®Œåç»Ÿä¸€å…³é—­èµ„æº
        page.close()
        context.close()
        browser.close()

    return failed_ids



# ==== ä¸»å…¥å£ ====
if __name__ == "__main__":
    print("=" * 60)
    print("ğŸš€ IMDbæ‰¹é‡HTMLä¿å­˜å™¨ï¼ˆå•è¿›ç¨‹é¡ºåºç‰ˆï¼‰")
    print("=" * 60)

    imdb_ids = read_imdb_ids_from_file(IMDB_ID_FILE)
    if not imdb_ids:
        print("âš ï¸ æ— æœ‰æ•ˆIMDb IDï¼Œé€€å‡º")
        exit()

    start = time.time()
    failed_ids = fetch_all_sequential(imdb_ids, OUTPUT_DIR)

    print("\nğŸ“Š æ€»è®¡å¤„ç†: ", len(imdb_ids))
    print("âœ… æˆåŠŸæ•°é‡: ", len(imdb_ids) - len(failed_ids))
    print("âŒ å¤±è´¥æ•°é‡: ", len(failed_ids))
    print(f"â±ï¸ ç”¨æ—¶: {int(time.time() - start)} ç§’")

    if failed_ids:
        with open(FAILED_FILE, "w", encoding="utf-8") as f:
            f.write("\n".join(failed_ids))
        print(f"\nğŸ“ å¤±è´¥IDå·²ä¿å­˜è‡³: {FAILED_FILE}")

    print("\nğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼æŒ‰Enteré”®é€€å‡º...")
    input()
